import streamlit as st
import os
import time
import requests
from dotenv import load_dotenv
from crewai import Agent, Task, Crew
from langchain_groq import ChatGroq
from crewai_tools import tool, ScrapeWebsiteTool
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.prompts import ChatPromptTemplate
from langchain.chains import create_retrieval_chain
from langchain_community.vectorstores import FAISS

# Carregar vari√°veis de ambiente
load_dotenv()
groq_api_key = os.environ.get("GROQ_API_KEY")

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="Sistema de Suporte √† V√≠tima e Assistente Jur√≠dico",
    page_icon="‚öñÔ∏è",
    layout="wide"
)

# Estilo CSS personalizado
st.markdown("""
    <style>
        .reportview-container {
            background-color: #f0f2f6;
        }
        .big-font {
            font-size:20px !important;
            font-weight: bold;
        }
        .stTabs [data-baseweb="tab-list"] {
            gap: 24px;
        }
        .stTabs [data-baseweb="tab"] {
            height: 50px;
            padding-top: 10px;
            padding-bottom: 10px;
        }
    </style>
""", unsafe_allow_html=True)

# Fun√ß√£o para carregar PDFs
def carregar_pdfs(pasta="pdfs"):
    if not os.path.exists(pasta):
        st.error(f"Erro: A pasta '{pasta}' n√£o foi encontrada.")
        return []
    
    arquivos_pdf = [os.path.join(pasta, f) for f in os.listdir(pasta) if f.lower().endswith('.pdf')]
    if arquivos_pdf:
        st.info(f"{len(arquivos_pdf)} arquivos PDF encontrados na pasta '{pasta}'.")
        return arquivos_pdf
    else:
        st.error(f"Erro: Nenhum arquivo PDF encontrado na pasta '{pasta}'.")
        return []

# Fun√ß√£o de configura√ß√£o do LLM
@st.cache_resource
def get_llm():
    return ChatGroq(
        temperature=0,
        model_name="llama3-70b-8192",
        api_key=groq_api_key
    )

# Fun√ß√£o para buscar delegacias
@tool
def buscar_delegacias_proximas(endereco_busca: str) -> str:
    """
    Busca delegacias de pol√≠cia pr√≥ximas a um endere√ßo fornecido.

    Par√¢metros:
    endereco_busca (str): Endere√ßo para a busca de delegacias pr√≥ximas.

    Retorno:
    str: Lista de delegacias encontradas ou uma mensagem de erro caso ocorra uma falha na requisi√ß√£o.
    """
    api_key = "9e65dad0b5342f127b90b31b40f4911f85d37019"
    url = "https://google.serper.dev/search"
    headers = {
        "X-API-KEY": api_key,
        "Content-Type": "application/json"
    }
    payload = {"q": f"delegacia de pol√≠cia perto de {endereco_busca}", "gl": "br", "hl": "pt"}

    try:
        response = requests.post(url, headers=headers, json=payload)
        response.raise_for_status()
        
        results = response.json()
        places = results.get('places', [])
        output = ""

        if places:
            for place in places:
                nome = place.get('title', 'N√£o dispon√≠vel')
                endereco = place.get('address', 'N√£o dispon√≠vel')
                cid = place.get('cid', 'N√£o dispon√≠vel')

                if 'delegacia' in nome.lower() or 'pol√≠cia' in nome.lower() or "distrito policial" in nome.lower():
                    google_maps_link = f"https://www.google.com/maps?q={endereco.replace(' ', '+')}"
                    output += f"Nome: {nome}\nEndere√ßo: {endereco}\nCID: {cid}\nLink do Google Maps: {google_maps_link}\n\n"
        else:
            output = "Nenhuma delegacia encontrada na regi√£o."
        
        return output
    
    except requests.exceptions.RequestException as e:
        return f"Erro na busca: {str(e)}"

# Fun√ß√£o para executar o crew de localiza√ß√£o
def executar_crew_localizacao(endereco):
    llm = get_llm()
    identificador = Agent(
        llm=llm,
        role="Identificador de Delegacias",
        goal=f"Localizar quais s√£o as delegacias mais pr√≥ximas de {endereco}",
        backstory=f"Conhece a regi√£o do endere√ßo ({endereco}) muito bem e pode auxiliar a v√≠tima",
        allow_delegation=False,
        verbose=True,
        tools=[buscar_delegacias_proximas]
    )
    escritor = Agent(
        llm=llm,
        role="Agente de Suporte de V√≠timas",
        goal="Escrever uma mensagem emp√°tica indicando as delegacias mais pr√≥ximas para que a v√≠tima preste queixa",
        backstory="Psic√≥logo experiente, emp√°tico e assertivo em suas sugest√µes.",
        allow_delegation=False,
        verbose=True
    )
    identificar_delegacias = Task(description=f"Liste as delegacias mais pr√≥ximas da v√≠tima localizada em {endereco}.", expected_output="Uma lista com as localidades mais pr√≥ximas.", agent=identificador)
    escrita = Task(description="Escreva uma resposta emp√°tica indicando as delegacias pr√≥ximas da v√≠tima.", expected_output="Mensagem listando as delegacias pr√≥ximas.", agent=escritor)
    crew = Crew(agents=[identificador, escritor], tasks=[identificar_delegacias, escrita], verbose=2)

    return crew.kickoff(inputs={"endereco": endereco})

# Fun√ß√£o para executar o crew de den√∫ncia
def executar_crew_denuncia(victim_name, conversation_text):
    llm = get_llm()
    
    estrutura = Agent(
        llm=llm,
        role="Especialista em Estrutura√ß√£o de Documentos de Den√∫ncia",
        goal="Estruturar um documento de den√∫ncia de viol√™ncia contra a mulher seguindo padr√µes t√©cnicos e jur√≠dicos",
        backstory=f"Especialista em documenta√ß√£o jur√≠dica auxiliando {victim_name}.",
        allow_delegation=False,
        verbose=True
    )
    
    escritor = Agent(
        llm=llm,
        role="Redator Jur√≠dico Especializado em Den√∫ncias",
        goal="Transformar relatos e evid√™ncias em um documento formal",
        backstory=f"Redator jur√≠dico ajudando {victim_name}.",
        allow_delegation=False,
        verbose=True
    )
    
    jurista = Agent(
        llm=llm,
        role="Especialista em Lei Maria da Penha",
        goal="Classificar viola√ß√µes e recomendar medidas legais apropriadas",
        backstory=f"Jurista especializado em viol√™ncia de g√™nero analisando o caso de {victim_name}.",
        allow_delegation=False,
        verbose=True
    )

    analisar_violencia = Task(
        description="Analise o relato e classifique o ocorrido conforme a Lei Maria da Penha.",
        expected_output="Relat√≥rio jur√≠dico da an√°lise.",
        agent=jurista
    )
    
    planejamento = Task(
        description="Elabore um modelo de documento para den√∫ncia de viol√™ncia com base no relato.",
        expected_output="Plano de den√∫ncia.",
        agent=estrutura
    )
    
    escrita = Task(
        description=f"Redija o documento de den√∫ncia para {victim_name}.",
        expected_output="Documento de den√∫ncia estruturado.",
        agent=escritor
    )
    
    crew = Crew(
        agents=[jurista, estrutura, escritor],
        tasks=[analisar_violencia, planejamento, escrita],
        verbose=2
    )

    # Corre√ß√£o: usar "victim_name" no dicion√°rio de inputs
    return crew.kickoff(inputs={
        "victim_name": victim_name,
        "conversation": conversation_text
    })


# Configura√ß√£o da interface com abas
tabs = st.tabs(["üöî Localizar Delegacias", "üìù Criar Den√∫ncia", "üëÆ‚Äç‚ôÄÔ∏è Assistente Lei Maria da Penha"])

# Aba 1: Localizar Delegacias
with tabs[0]:
    st.title("üöî Localizador de Delegacias Pr√≥ximas")
    st.markdown("### Encontre delegacias pr√≥ximas √† sua localiza√ß√£o")
    with st.form("busca_form"):
        endereco = st.text_input("Digite seu endere√ßo", placeholder="Ex: Rua MMDC, 80, Butant√£, S√£o Paulo")
        submitted_localizacao = st.form_submit_button("üîç Buscar Delegacias")
    if submitted_localizacao and endereco:
        with st.spinner('Buscando delegacias pr√≥ximas...'):
            try:
                resultado = executar_crew_localizacao(endereco)
                st.success("Busca realizada com sucesso!")
                st.markdown("### Resultado da Busca")
                st.write(resultado)
            except Exception as e:
                st.error(f"Ocorreu um erro durante a busca: {str(e)}")

# Aba 2: Criar Den√∫ncia
with tabs[1]:
    st.title("üìù Assistente de Den√∫ncia")
    st.markdown("### Aux√≠lio na cria√ß√£o do documento de den√∫ncia")
    with st.form("denuncia_form"):
        victim_name = st.text_input("Nome da V√≠tima", placeholder="Digite seu nome completo")
        conversation_text = st.text_area("Relato dos Acontecimentos", placeholder="Descreva detalhadamente os acontecimentos...", height=300)
        submitted_denuncia = st.form_submit_button("üìã Gerar Documento de Den√∫ncia")
    if submitted_denuncia and victim_name and conversation_text:
        with st.spinner('Gerando documento de den√∫ncia...'):
            try:
                resultado = executar_crew_denuncia(victim_name, conversation_text)
                st.success("Documento gerado com sucesso!")
                st.markdown("### Documento de Den√∫ncia")
                st.write(resultado)
            except Exception as e:
                st.error(f"Ocorreu um erro durante a gera√ß√£o do documento: {str(e)}")

# Aba 3: Assistente Lei Maria da Penha
with tabs[2]:
    st.title("üëÆ‚Äç‚ôÄÔ∏è Assistente Virtual - Lei Maria da Penha")
    st.subheader("Tire suas d√∫vidas sobre a Lei Maria da Penha")
    
    if "messages" not in st.session_state:
        st.session_state.messages = [{"role": "assistant", "content": "Ol√°! Eu sou seu Assistente Virtual sobre a Lei Maria da Penha. Aconteceu algo com que posso ajudar?"}]
    
    arquivos_pdf = carregar_pdfs()
    
    if arquivos_pdf:
            try:
                # Configura√ß√£o inicial do chat
                if "chat_initialized" not in st.session_state:
                    with st.spinner("Inicializando o assistente..."):
                        model_name = "sentence-transformers/all-MiniLM-L6-v2"
                        embeddings = HuggingFaceEmbeddings(model_name=model_name, model_kwargs={'device': 'cpu'})
                        
                        # Carregar e dividir documentos de todos os PDFs
                        final_documents = []
                        for arquivo_pdf in arquivos_pdf:
                            loader = PyPDFLoader(arquivo_pdf)
                            docs = loader.load()
                            
                            text_splitter = RecursiveCharacterTextSplitter(
                                chunk_size=1000,
                                chunk_overlap=200,
                                separators=["\n\n", "\n", ".", "!", "?", ";", ",", " "]
                            )
                            final_documents.extend(text_splitter.split_documents(docs))
                        
                        vectors = FAISS.from_documents(final_documents, embeddings)
                        
                        # Configurar LLM e prompt
                        llm = ChatGroq(
                            groq_api_key=groq_api_key,
                            model_name="llama3-70b-8192",
                            temperature=0.1
                        )

                        prompt = ChatPromptTemplate.from_template("""
                        Voc√™ √© uma assistente especializada na Lei Maria da Penha (Lei n¬∫ 11.340/2006) e deseja entender o m√°ximo de detalhes sobre a situa√ß√£o da pessoa que est√° em contato com voc√™.
                        Responda √† pergunta de maneira emp√°tica e fa√ßa perguntas que ajudem a entender melhor a situa√ß√£o da v√≠tima, sempre buscando obter mais detalhes e mostrando compreens√£o.

                        Algumas diretrizes para sua resposta:
                        - Use linguagem acess√≠vel, evitando jarg√µes jur√≠dicos complexos
                        - Se a situa√ß√£o envolver risco, pergunte se a pessoa j√° buscou ajuda e ofere√ßa informa√ß√µes sobre canais de apoio
                        - Mantenha-se estritamente dentro do conte√∫do da lei fornecido no contexto
                        - Finalize cada resposta com uma pergunta, incentivando a continuidade da conversa e a obten√ß√£o de mais detalhes sobre a situa√ß√£o. Fa√ßa apenas uma pergunta por mensagem.
                        - Antes de perguntar, ajude ela com as medidas legais com base na lei maria da penha.

                        <contexto>
                        {context}
                        </contexto>

                        Pergunta: {input}
                        Hist√≥rico da Conversa: {history}
                        """)


                        # Criar chains
                        document_chain = create_stuff_documents_chain(llm, prompt)
                        retriever = vectors.as_retriever(search_kwargs={"k": 4})
                        st.session_state.retrieval_chain = create_retrieval_chain(retriever, document_chain)
                        st.session_state.chat_initialized = True

                # Display chat messages
                for message in st.session_state.messages:
                    with st.chat_message(message["role"]):
                        st.write(message["content"])

                # Chat input
                if pergunta := st.chat_input("Digite sua pergunta sobre a Lei Maria da Penha"):
                    # Add user message to chat history
                    st.session_state.messages.append({"role": "user", "content": pergunta})
                    with st.chat_message("user"):
                        st.write(pergunta)

                    # Gerar hist√≥rico da conversa
                    history = "\n".join([f"{msg['role']}: {msg['content']}" for msg in st.session_state.messages])

                    # Generate and display assistant response
                    with st.chat_message("assistant"):
                        with st.spinner("Analisando sua pergunta..."):
                            start = time.time()
                            response = st.session_state.retrieval_chain.invoke({"input": pergunta, "history": history})
                            tempo = time.time() - start
                            
                            st.write(response['answer'])
                            st.caption(f"Tempo de resposta: {tempo:.2f} segundos")
                    
                    # Add assistant response to chat history
                    st.session_state.messages.append({"role": "assistant", "content": response['answer']})

            except Exception as e:
                st.error(f"Ocorreu um erro ao processar sua solicita√ß√£o: {str(e)}")


# Rodap√©
st.markdown("---")
st.markdown("Desenvolvido para auxiliar v√≠timas de viol√™ncia. Ligue 180 para a Central de Atendimento √† Mulher.", help="Este √© um servi√ßo de utilidade p√∫blica")
